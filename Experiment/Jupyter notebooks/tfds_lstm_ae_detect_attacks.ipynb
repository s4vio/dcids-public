{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe717fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "import numpy as np\n",
    "np.set_printoptions(suppress=True) #prevent numpy exponential\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "#from pathlib import Path\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer, MinMaxScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow import keras\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "#from keras import optimizers, Sequential, metrics\n",
    "from elasticsearch import Elasticsearch\n",
    "from espandas import Espandas\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import LSTM, Dense, RepeatVector, TimeDistributed, Conv1D\n",
    "from tensorflow.compat.v1.keras.layers import CuDNNLSTM\n",
    "from keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping\n",
    "from ipynb.fs.full.rcids_functions import *\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "np.set_printoptions(suppress=True) #prevent numpy exponential\n",
    "pd.set_option('display.float_format', lambda x: '%.4f' % x) #prevent scientific notation in pandas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2641b858",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tensorflow.python.client import device_lib\n",
    "#print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23297f5b",
   "metadata": {},
   "source": [
    "### Reading from Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70348c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test conectivity with Elasticsearch\n",
    "es = Elasticsearch(host=\"192.168.201.2\", http_auth=(\"elastic\",\"##redacted##\"))\n",
    "#es.info(pretty=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3870410b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining elasticsearch indice to read from\n",
    "\n",
    "#attack_name = \"bruteforcelogin\"\n",
    "#attack_name = \"dockerescape\"\n",
    "#attack_name = \"maliciousscript\"\n",
    "#attack_name = \"meterpreter\"\n",
    "#attack_name = \"remoteshell\"\n",
    "#attack_name = \"sqlinjection\"\n",
    "#attack_name = \"sqlmisbehavior\"\n",
    "\n",
    "index = \"proc-public-\" + str(attack_name)\n",
    "\n",
    "# Counting number of documents in index\n",
    "n_docs = es.count(index=index)\n",
    "print(\"Number of documents in the index \", index, \"-->\", n_docs['count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f61ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dataset for trainning\n",
    "df_attack = read_from_elastic(index, es)\n",
    "df_attack.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c4469d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preserving timestamp column on a new dataframe\n",
    "df_attack_timestamp = pd.DataFrame()\n",
    "df_attack_timestamp['timestamp'] = df_attack['timestamp']\n",
    "\n",
    "# Excluding timestamp column\n",
    "df_attack.drop(['timestamp'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2afe16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining window_size and n_feature\n",
    "window_size = 6\n",
    "n_features = df_attack.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e21806",
   "metadata": {},
   "source": [
    "## Pre-processing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b81233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing data\n",
    "\n",
    "# Loading existent df from disk\n",
    "df_benign_data = pd.read_pickle(\"pkl/df_proc_benign_data.pkl\")\n",
    "\n",
    "# Normalizing attack data\n",
    "#norm = Normalizer()\n",
    "#norm_attack = norm.fit(df_benign_data)\n",
    "#attack = norm_attack.transform(df_attack)\n",
    "\n",
    "mm = MinMaxScaler()\n",
    "mm_attack = mm.fit(df_benign_data)\n",
    "attack = mm_attack.transform(df_attack)\n",
    "\n",
    "print(attack_name, \"numpy.ndarray shape:\", attack.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ce46ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating 3D array for train data\n",
    "# For an LSTM Autoencoder the shape of input has to be of the format: n_samples x window_size x n_features\n",
    "attack_wz = pd.DataFrame(attack)\n",
    "attack_wz = sliding_window(attack_wz, window_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e17f96",
   "metadata": {},
   "source": [
    "## Creating Tensorflow datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f65c8c6",
   "metadata": {},
   "source": [
    "### Attack dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17098ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attack dataset\n",
    "ds_attack = tf.data.Dataset.from_tensor_slices(attack_wz)\n",
    "ds_attack = ds_attack.map(lambda x: (x, x))\n",
    "ds_attack_batch = ds_attack.batch(1024).cache().prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5d2bda",
   "metadata": {},
   "source": [
    "## Loading the trainned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1e03c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'tfds_lstm_160_64_24_conv1d_relu_5_bn_tahn_wz6_ft5_mm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce9b0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving/Loading the model\n",
    "filepath = 'models/model-' + str(model_name) + '.h5'\n",
    "model = load_model(filepath, compile=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3863f32",
   "metadata": {},
   "source": [
    "## Predicting test data using the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2dae0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting values using the trained model\n",
    "pred = model.predict(ds_attack_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0dd8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping array with predictions to 2D dataframe (column 2 x column 3)\n",
    "#X_pred.shape #--> (samples - window_size, window_size, n_features)\n",
    "pred = pred.reshape(pred.shape[0], pred.shape[1] * pred.shape[2])\n",
    "df_pred = pd.DataFrame(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef465774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping array with real data to 2D dataframe (column 2 x column 3)\n",
    "#X_test.shape # --> (samples - window_size, window_size, n_features)\n",
    "attack_2d = attack_wz.reshape(attack_wz.shape[0], attack_wz.shape[1] * attack_wz.shape[2])\n",
    "df_attack_2d = pd.DataFrame(attack_2d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7ce94c",
   "metadata": {},
   "source": [
    "### Calculating the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fe3c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating test loss with MAE (Mean Absolute Error)\n",
    "df_test_loss = pd.DataFrame(index=df_pred.index)\n",
    "df_test_loss['Loss_mae'] = tf.metrics.MAE(df_attack_2d, df_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4067c260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the loss distribution\n",
    "plot = sns.displot(data=df_test_loss['Loss_mae'], kind='kde', color='blue', height=5, aspect=2)\n",
    "plot.set_axis_labels(\"Loss\", \"Density\")\n",
    "plot.set(title='Loss Distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01cf8d0c",
   "metadata": {},
   "source": [
    "## Malicious data x Loss Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edacb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading thresholds dataframe\n",
    "df_thresholds = pd.read_pickle('pkl/df_thresholds.pkl')\n",
    "df_thresholds.groupby(['Model']).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c5e3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confidence level e threshold escolhidos a partir dos valores obtidos com dados de teste\n",
    "confidence_level = 0.99\n",
    "loss_threshold = 0.0164"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6ff94c",
   "metadata": {},
   "source": [
    "### Verifying test data loss against defined threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0044c92c",
   "metadata": {},
   "source": [
    "#### Labeling Malicious Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3681fe7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating rows (windows) hash\n",
    "attack_hash = df_attack_2d.apply(lambda x: hash(tuple(x)).to_bytes(8, \"big\", signed=True).hex(), axis=1)\n",
    "df_attack_hash = pd.DataFrame(attack_hash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d8fc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading benign_hashdb\n",
    "df_bening_hashdb = pd.read_pickle('pkl/df_proc_benign_hashdb_wz6_ft5_mm.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496abca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check existence of hashes in benign_hashdb\n",
    "df_attack_hash.shape, df_attack_hash[0].isin(df_bening_hashdb[0]).value_counts(), df_attack_hash[0].isin(df_bening_hashdb[0]).value_counts(normalize=True).mul(100).round(3).astype(str) + '%'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea8a424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding real label to df_test_loss\n",
    "df_test_loss['real'] = ~df_attack_hash[0].isin(df_bening_hashdb[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b58825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dataframe with test data results\n",
    "df_test_results = window_loss(df_test_loss, loss_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd040a1f",
   "metadata": {},
   "source": [
    "### Ploting loss of the test data prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324dce50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the test data x loss threshold\n",
    "df_test_results_plot = df_test_results[['window_number', 'loss']]\n",
    "df_test_results_plot.plot(kind='line', marker= 'H', x='window_number', y='loss', ylabel='Loss', xlabel='Window number', figsize=(20, 7)).axhline(y=loss_threshold, linewidth= 1, color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af8f2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_results['anomaly'].value_counts(), df_test_results['anomaly'].value_counts(normalize=True).mul(100).round(2).astype(str) + '%'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3e207b",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62349d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing metrics results\n",
    "cm, accuracy, precision, tpr, npv, tnr, fpr, f1, roc_auc = metrics(df_test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6529a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- MÉTRICAS ---\")\n",
    "print(\"Acurácia:\", np.round(accuracy * 100, 2), \"%\")\n",
    "print(\"Precisão:\", np.round(precision * 100, 2), \"%\")\n",
    "print(\"TPR ou Recall:\", np.round(tpr * 100, 2), \"%\")\n",
    "print(\"NPV:\", np.round(npv * 100, 2), \"%\")\n",
    "print(\"TNR ou Especificidade:\", np.round(tnr * 100, 2), \"%\")\n",
    "print(\"FPR ou FAR:\", np.round(fpr * 100, 2), \"%\")\n",
    "print(\"F1 Score:\", np.round(f1 * 100, 2), \"%\")\n",
    "print(\"ROC AUC:\", np.round(roc_auc * 100, 2), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a4d145",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = ConfusionMatrixDisplay(cm, display_labels=['Normal','Anomaly'])\n",
    "cmd.plot(cmap=\"Blues\", values_format='', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88d10fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_roc, tpr_roc, _ = roc_curve(df_test_results['real'], df_test_results['anomaly'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fca197b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr_roc, tpr_roc, label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2fd934",
   "metadata": {},
   "source": [
    "### Saving metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1b41d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile('pkl/df_metrics_exp1.pkl'): \n",
    "    # Loading existent df from disk\n",
    "    df_metrics = pd.read_pickle('pkl/df_metrics_exp1.pkl')\n",
    "else:\n",
    "    # Defining dataframe columns\n",
    "    df_metrics = pd.DataFrame(columns=[\"Model\",\"Attack\",\"Confidence_Level\",\"Threshold\",\"Accuracy\",\"Precision\",\"TPR\",\"NPV\",\"TNR\",\"FPR\",\"F1-Score\",\"ROC-AUC\",\"CM\"])\n",
    "\n",
    "# Removing ./ from model name \n",
    "#filepath = filepath.replace('./',\"\")\n",
    "\n",
    "# Adding last execution results in to dataframe\n",
    "df_metrics.loc[df_metrics.shape[0]] = [filepath, attack_name, confidence_level, loss_threshold, accuracy, precision, tpr, npv, tnr, fpr, f1, roc_auc, cm]\n",
    "\n",
    "# Saving df to disk\n",
    "df_metrics.to_pickle('pkl/df_metrics_exp1.pkl')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ad7d94ed",
   "metadata": {},
   "source": [
    "### Checking the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8e1c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics[['Attack', 'Accuracy', 'NPV', 'TPR', 'FPR', 'Confidence_Level', 'Model']].sort_values(['Attack', 'Accuracy'], ascending=([True, False])).groupby('Attack').head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec2fd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics.sort_values(['Attack', 'Accuracy'], ascending=([True, False])).groupby('Attack').head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394057cd",
   "metadata": {},
   "source": [
    "### Writing results in Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec18e739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test conectivity with Elasticsearch\n",
    "es = Elasticsearch(host=\"192.168.201.2\", http_auth=(\"elastic\",\"##redacted##\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510727cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating index with each window loss\n",
    "index = \"proc-public-\" + str(attack_name)\n",
    "index = \"scan-\" + str(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fced56b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copying df_test_results to a new dataframe before sending to Elastic\n",
    "df_result_es = df_test_results.copy()\n",
    "\n",
    "# The dataframe to insert in elasticsearch must have a column with name 'indexId' (https://github.com/dashaub/espandas#usage)\n",
    "df_result_es['indexId'] = df_result_es.index.astype(str)\n",
    "\n",
    "# Removing window_number column to reduce size of dataframe\n",
    "df_result_es.drop(['window_number'], axis=1, inplace=True)\n",
    "\n",
    "# Coverting 'anomaly' colum to string lower case due to Elastic requirements for boolean mapping type\n",
    "df_result_es['anomaly'] = df_result_es['anomaly'].astype('string').str.lower()\n",
    "\n",
    "# Adding chosen loss threshold to the dataframe\n",
    "df_result_es['threshold'] = loss_threshold\n",
    "\n",
    "# Adding chosen confidence_interval to the dataframe\n",
    "df_result_es['confidence_level'] = confidence_level\n",
    "\n",
    "# Adding the timestamp of the first system call in window to the dataframe\n",
    "df_result_es.loc[:, 'timestamp'] = df_attack_timestamp.loc[:, 'timestamp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788e7051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuring Elastic credentials\n",
    "esp = Espandas(host=\"192.168.201.2\", http_auth=(\"elastic\",\"##redacted##\"))\n",
    "\n",
    "# Writing index in Elastic\n",
    "esp.es_write(df_result_es, index=index, doc_type=None)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 (main, Dec  7 2022, 00:00:00) [GCC 12.2.1 20221121 (Red Hat 12.2.1-4)]"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
